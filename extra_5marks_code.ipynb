{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "# import sys\n",
    "\n",
    "# # List of required libraries\n",
    "# required_libraries = [\n",
    "#     \"numpy\",\n",
    "#     \"librosa\",\n",
    "#     \"scikit-learn\"\n",
    "# ]\n",
    "\n",
    "# def install_libraries(libraries):\n",
    "#     \"\"\"Install a list of libraries using pip.\"\"\"\n",
    "#     for library in libraries:\n",
    "#         try:\n",
    "#             # Use subprocess to run pip install command\n",
    "#             subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", library])\n",
    "#             print(f\"Successfully installed {library}\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error installing {library}: {e}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     install_libraries(required_libraries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract basic MFCC features from an audio file without any further normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. use of Mel-Frequency Filtering \n",
    "2. unscaled the data , the given code scaled the voice but that feature is only good for test cases with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "def extract_mfcc_features(file_path, n_mfcc=13):\n",
    "    \n",
    "    try:\n",
    "        # Load the audio file\n",
    "        y, sr = librosa.load(file_path, sr=None)\n",
    "        # Compute MFCC features\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        # Return the mean MFCC features across time\n",
    "        return np.mean(mfcc.T, axis=0)  # Mean across time axis to summarize\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load features for a single speaker from their audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_speaker_features(speaker_folder):\n",
    "    \n",
    "    speaker_features = []  # Initialize a list to store features of the speaker\n",
    "    speaker_name = os.path.basename(speaker_folder)  # Get the folder name as the speaker name\n",
    "\n",
    "    # Iterate through all files in the speaker's folder\n",
    "    for file in os.listdir(speaker_folder):\n",
    "        if file.endswith('.wav'):  # Process only WAV files\n",
    "            file_path = os.path.join(speaker_folder, file)\n",
    "            mfcc = extract_mfcc_features(file_path)  # Extract MFCC features\n",
    "            if mfcc is not None:\n",
    "                speaker_features.append((file, mfcc))  # Store both file name and features\n",
    "\n",
    "    return speaker_name, speaker_features  # Return speaker name and features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load audio data and filter speakers based on the minimum number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_with_filter(path, min_samples=2):\n",
    "    speakers = []  # List to store speaker labels\n",
    "    features = []  # List to store features for each speaker\n",
    "\n",
    "    speaker_labels = {}  # Dictionary to store speaker labels\n",
    "    label_counter = 1    # Start labeling speakers from 1 to 7\n",
    "\n",
    "    # Iterate through all folders in the given path (each folder represents a speaker)\n",
    "    for speaker in os.listdir(path):\n",
    "        speaker_folder = os.path.join(path, speaker)\n",
    "        if os.path.isdir(speaker_folder):  # Check if it's a directory\n",
    "            speaker_name, speaker_features = load_speaker_features(speaker_folder)\n",
    "            if len(speaker_features) >= min_samples:  # Filter based on minimum samples\n",
    "                if label_counter <= 7:  # Limit to 7 speakers\n",
    "                    speaker_labels[speaker_name] = str(label_counter)  # Assign label 1-7\n",
    "                    label_counter += 1\n",
    "                    features.append(speaker_features)  # Store tuples of (file, features)\n",
    "                    speakers.append(speaker_labels[speaker_name])  # Add numeric label for this speaker\n",
    "\n",
    "    return speakers, features  # Return lists of speakers and their features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a Gaussian Mixture Model on the given features.\n",
    "#### Train GMM models for each speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gmm(features, n_components=1, reg_covar=1e-2):\n",
    "    \n",
    "    # Create a Gaussian Mixture Model\n",
    "    gmm = GaussianMixture(n_components=n_components, covariance_type='diag', \n",
    "                          reg_covar=reg_covar, max_iter=500, random_state=0)\n",
    "    gmm.fit(features)  # Fit the model to the features\n",
    "    return gmm  # Return the trained GMM\n",
    "\n",
    "def train_gmm_models(train_features, n_components=1, reg_covar=1e-2):\n",
    "    \n",
    "    # Train a GMM for each speaker using their extracted features\n",
    "    gmms = [train_gmm(np.array([mfcc for _, mfcc in speaker_features]), n_components, reg_covar) \n",
    "            for speaker_features in train_features]\n",
    "    return gmms  # Return the list of GMMs for each speaker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the speaker based on the test features.\n",
    "### Identify speakers for test files and return predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_speaker(test_features, gmms, speakers):\n",
    "    \n",
    "    test_features = test_features.reshape(1, -1)  # Reshape the test feature array for GMM prediction\n",
    "    scores = [gmm.score(test_features) for gmm in gmms]  # Compute scores for each GMM\n",
    "    best_match = np.argmax(scores)  # Get the index of the best score\n",
    "    return speakers[best_match], scores[best_match]  # Return the best speaker and corresponding score\n",
    "\n",
    "def identify_speakers(test_features_scaled, gmms, train_speakers):\n",
    "    \n",
    "    predictions = []  # List to store predictions\n",
    "\n",
    "    for test_sample in test_features_scaled:\n",
    "        for file_name, sample in test_sample:\n",
    "            identified_speaker, score = identify_speaker(sample, gmms, train_speakers)  # Identify speaker\n",
    "            prediction = {'file': file_name, 'speaker': identified_speaker, 'score': score}  # Store prediction\n",
    "            predictions.append(prediction)  # Add to predictions list\n",
    "\n",
    "    return predictions  # Return the list of predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here speakers are identified by numbers along with the file name and the predictions are pretty much accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing training data...\n",
      "Training GMM models for each speaker...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\itsja\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\itsja\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\itsja\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\itsja\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\itsja\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\itsja\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing test data...\n",
      "Identifying speakers from test data...\n",
      "\n",
      "Prediction Results:\n",
      "Test File: Abhay_15.wav -> Identified Speaker: 1, Score: -92.46\n",
      "Test File: Abhay_16.wav -> Identified Speaker: 1, Score: -130.84\n",
      "Test File: Abhay_17.wav -> Identified Speaker: 5, Score: -91.84\n",
      "Test File: Abhay_18.wav -> Identified Speaker: 5, Score: -61.28\n",
      "Test File: Abhay_19.wav -> Identified Speaker: 5, Score: -44.62\n",
      "Test File: P1.wav -> Identified Speaker: 3, Score: -111.48\n",
      "Test File: piggu.wav -> Identified Speaker: 3, Score: -40.07\n",
      "Test File: Rg_16.wav -> Identified Speaker: 3, Score: -42.41\n",
      "Test File: Rg_17.wav -> Identified Speaker: 3, Score: -51.61\n",
      "Test File: Rg_18.wav -> Identified Speaker: 3, Score: -54.33\n",
      "Test File: Rg_19.wav -> Identified Speaker: 3, Score: -50.99\n",
      "Test File: Rg_20.wav -> Identified Speaker: 3, Score: -53.51\n",
      "Test File: chappu_10.wav -> Identified Speaker: 5, Score: -35.92\n",
      "Test File: chappu_6.wav -> Identified Speaker: 5, Score: -37.75\n",
      "Test File: chappu_7.wav -> Identified Speaker: 5, Score: -47.30\n",
      "Test File: chappu_8.wav -> Identified Speaker: 5, Score: -39.74\n",
      "Test File: chappu_9.wav -> Identified Speaker: 5, Score: -39.07\n",
      "Test File: P5.wav -> Identified Speaker: 5, Score: -37.42\n",
      "Test File: P6.wav -> Identified Speaker: 5, Score: -65.50\n",
      "Test File: Vaibhav_16.wav -> Identified Speaker: 6, Score: -39.92\n",
      "Test File: Vaibhav_17.wav -> Identified Speaker: 6, Score: -37.08\n",
      "Test File: Vaibhav_18.wav -> Identified Speaker: 6, Score: -35.12\n",
      "Test File: Vaibhav_19.wav -> Identified Speaker: 6, Score: -51.98\n",
      "Test File: Vaibhav_20.wav -> Identified Speaker: 5, Score: -70.87\n"
     ]
    }
   ],
   "source": [
    "def main(train_data_path, test_data_path, n_components=1):\n",
    "    # Load and filter the training data\n",
    "    print(\"Loading and preparing training data...\")\n",
    "    train_speakers, train_features = load_data_with_filter(train_data_path, min_samples=3)\n",
    "\n",
    "    # Train the GMM models for each speaker using unscaled MFCC features\n",
    "    print(\"Training GMM models for each speaker...\")\n",
    "    gmms = train_gmm_models(train_features, n_components=n_components, reg_covar=1e-2)\n",
    "\n",
    "    # Load and filter the test data\n",
    "    print(\"Loading and preparing test data...\")\n",
    "    test_speakers, test_features = load_data_with_filter(test_data_path, min_samples=1)\n",
    "\n",
    "    # Identify speakers for each test file\n",
    "    print(\"Identifying speakers from test data...\")\n",
    "    predictions = identify_speakers(test_features, gmms, train_speakers)\n",
    "\n",
    "    # Print the identified speakers along with scores and test file names\n",
    "    print(\"\\nPrediction Results:\")\n",
    "    for pred in predictions:\n",
    "        print(f\"Test File: {pred['file']} -> Identified Speaker: {pred['speaker']}, Score: {pred['score']:.2f}\")\n",
    "\n",
    "# Paths to the training and testing data\n",
    "train_data_path = 'Voice_Samples_training'  # Path to training data\n",
    "test_data_path = 'Testing_Audio'  # Path to testing data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(train_data_path, test_data_path, n_components=1)  # Run the main function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Human voice closely resembles that of gaussian distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### un normalized sound is better when datapoints are less and our aim is to identify the speaker not the word he/she speak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When we want to distinguish the word spoken or we have to do speech to text applications It's best to normalize  the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are some other methods of prediction also like linear interpolation to get an idea of voice function but that method will be helpful  more when speech to txt applications are there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SPeech to text is actually very easy and do not require huge datasets as I used to assume only nomalizing the voice will be better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Any small variation in the training data may also have a huge damage when speaker identification is there it is best to keep it as untouched as possible"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
